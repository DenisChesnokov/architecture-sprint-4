# Архитектурное решение по логированию

## Анализ необходимости логирования

### Системы для логирования

1. **Internet Shop & Shop API:**
   - Действия пользователей с заказами
   - Загрузка и обработка 3D-моделей
   - API вызовы и ошибки

2. **MES & MES API:**
   - Расчет стоимости заказов
   - Действия операторов
   - Изменения статусов производства

3. **CRM & CRM API:**
   - Действия менеджеров
   - Подтверждения заказов
   - Интеграционные события

4. **RabbitMQ:**
   - Отправка/получение сообщений
   - Ошибки маршрутизации
   - Dead letter события

### Необходимые логи уровня INFO

1. Заказы
2. 3D Модели
3. Производство


### Другие уровни логирования

1. **DEBUG:**
   - Детали расчета стоимости
   - Процесс обработки 3D-модели
   - Подробности интеграционных вызовов

2. **WARN:**
   - Повторные попытки операций
   - Превышение ожидаемого времени выполнения
   - Нестандартные ситуации в бизнес-процессах

3. **ERROR:**
   - Ошибки интеграции
   - Проблемы с расчетом стоимости
   - Сбои в обработке заказов

4. **FATAL:**
   - Критические сбои сервисов
   - Потеря соединения с базами данных
   - Проблемы с очередями сообщений

## Мотивация

### Бизнес-выгоды
1. **Сокращение времени решения проблем**
   - Текущее состояние: часы/дни
   - Целевое состояние: минуты/часы

2. **Улучшение качества поддержки**
   - Проактивное обнаружение проблем
   - Точная диагностика issues
   - Предотвращение повторных проблем

3. **Оптимизация процессов**
   - Выявление узких мест
   - Анализ поведения пользователей
   - Улучшение бизнес-метрик

### Приоритизация внедрения

1. **Первая фаза (1-2 месяца):**
   - MES & MES API (критично для производства)
   - RabbitMQ (проблемы с потерей сообщений)

2. **Вторая фаза (2-3 месяца):**
   - Shop API (B2B интеграции)
   - CRM API (работа с клиентами)

3. **Третья фаза (3-4 месяца):**
   - Frontend приложения
   - Дополнительные интеграции

## Предлагаемое решение

### Технологический стек

1. **Сбор логов:**
   - Filebeat для файловых логов
   - Logstash для агрегации и обработки
   - Kafka для буферизации

2. **Хранение и анализ:**
   - Elasticsearch для хранения
   - Kibana для визуализации
   - Grafana для дашбордов

3. **Мониторинг:**
   - Prometheus для метрик
   - AlertManager для оповещений
   - Grafana для алертинга

[Схема](jewerly_c4_model.drawio)

### Политика безопасности

1. **Обработка чувствительных данных:**
   - Маскирование персональных данных (PII)
   - Шифрование в состоянии покоя
   - Аудит доступа к логам

2. **Уровни доступа:**
   - Admin: полный доступ
   - Support: чтение всех логов кроме security
   - Developer: доступ к логам своих сервисов
   - Business: доступ к бизнес-метрикам

### Политика хранения

1. **Структура индексов:**
   - Отдельный индекс для каждого сервиса
   - Ротация индексов по дням
   - Архивация старых логов

2. **Сроки хранения:**
   - Hot storage (30 дней): полные логи
   - Warm storage (90 дней): агрегированные данные
   - Cold storage (1 год): критические события

3. **Объемы данных:**
   - Ожидаемый объем: ~50GB/день
   - Ротация при достижении 80% места
   - Автоматическая архивация

## Аналитика и алертинг

### Алерты

1. **Бизнес-процессы:**
   - Аномальное количество заказов
   - Длительное время обработки
   - Высокий процент ошибок

2. **Технические проблемы:**
   - Ошибки интеграции
   - Проблемы с очередями
   - Сбои сервисов

### Поиск аномалий

1. **Паттерны атак:**
   - Резкий рост запросов
   - Необычные паттерны использования API
   - Подозрительные IP-адреса

2. **Бизнес-аномалии:**
   - Нестандартные суммы заказов
   - Аномальное поведение пользователей
   - Отклонения в процессах производства

### Автоматические действия

1. **При обнаружении DDoS:**
   - Включение WAF
   - Блокировка подозрительных IP
   - Уведомление security team

2. **При проблемах с производством:**
   - Автоматическое масштабирование
   - Перераспределение нагрузки
   - Оповещение операторов

3. **При бизнес-аномалиях:**
   - Создание инцидента
   - Уведомление ответственных лиц
   - Автоматический сбор данных для анализа